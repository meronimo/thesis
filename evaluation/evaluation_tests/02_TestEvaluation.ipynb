{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-13T15:48:14.867796Z",
     "start_time": "2024-06-13T15:48:07.344306Z"
    }
   },
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import nest_asyncio\n",
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "from llama_index.core.evaluation import PairwiseComparisonEvaluator\n",
    "from llama_index.core.evaluation.answer_relevancy import AnswerRelevancyEvaluator\n",
    "from llama_index.core.evaluation.context_relevancy import ContextRelevancyEvaluator\n",
    "from llama_index.core.evaluation.correctness import CorrectnessEvaluator\n",
    "from llama_index.core.evaluation.relevancy import RelevancyEvaluator\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from utils.config import OPENAI_API_KEY\n",
    "from utils.evaluation import (\n",
    "    get_all_test_data,\n",
    "    update_database,\n",
    "    update_evaluation,\n",
    "    get_current_evaluation\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded in: 0.0 seconds\n",
      "Debugging is enabled: True\n",
      "Device: cuda is available\n",
      "VectorStoreIndex: wiki_movie_plots\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:38:48.517193Z",
     "start_time": "2024-06-13T15:38:48.505165Z"
    }
   },
   "cell_type": "code",
   "source": "nest_asyncio.apply()",
   "id": "5a3059f3e72c7ec0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:38:49.533237Z",
     "start_time": "2024-06-13T15:38:49.519207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initialize logging for better debugging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ],
   "id": "6af15094ccde7502",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:38:53.803334Z",
     "start_time": "2024-06-13T15:38:53.792822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_record_data(record):\n",
    "    # init fields for evaluation of correctness via llama index framework\n",
    "    context = record[5]  # retrieved_contexts from the index\n",
    "    question = record[6]  # question asked by the user\n",
    "    reference_answer = record[7]  # reference_answer from the reference model gpt3\n",
    "    response = record[8]  # response from the llm model that we are evaluating\n",
    "    return context, question, reference_answer, response"
   ],
   "id": "fe8b879e39bd555a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T06:29:49.581144Z",
     "start_time": "2024-06-13T06:29:49.562424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_evaluation_model():\n",
    "    # init evaluation model\n",
    "    return OpenAI(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        temperature=0,\n",
    "    )"
   ],
   "id": "746801d00cb1e096",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T06:29:50.371504Z",
     "start_time": "2024-06-13T06:29:50.354473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_answer_relenvancy(evaluation_model, record):\n",
    "    \"\"\"\n",
    "    01 Answer Relevancy Evaluator\n",
    "    Evaluates the relevancy of response to a query.\n",
    "    This evaluator considers the query string and response string.\n",
    "\n",
    "    Metric: answer_relevancy_feedback (str)\n",
    "    \"\"\"\n",
    "    context, question, reference_answer, response = get_record_data(record)\n",
    "\n",
    "    # evaluation\n",
    "    evaluator = AnswerRelevancyEvaluator(llm=evaluation_model)\n",
    "    result = evaluator.evaluate(\n",
    "        query=question,  # query_string\n",
    "        response=response  # response_string\n",
    "    )\n",
    "\n",
    "    # fields to be updated in the database\n",
    "    fields = [\"answer_feedback\"]\n",
    "    # values to be updated in the database\n",
    "    values = [f\"{result.feedback}\"]\n",
    "\n",
    "    return fields, values"
   ],
   "id": "bd95afbc89154942",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T06:29:51.117239Z",
     "start_time": "2024-06-13T06:29:51.109236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_context_relevancy(evaluation_model, record):\n",
    "    \"\"\"\n",
    "    02 Context Relevancy Evaluator\n",
    "    Evaluates the relevancy of retrieved contexts to a query.\n",
    "    This evaluator considers the query string and retrieved contexts.\n",
    "\n",
    "    Metric:\n",
    "    context_relevancy_score (float)\n",
    "    context_relevancy_feedback (str)\n",
    "    \"\"\"\n",
    "    context, question, reference_answer, response = get_record_data(record)\n",
    "\n",
    "    # evaluation\n",
    "    evaluator = ContextRelevancyEvaluator(llm=evaluation_model)\n",
    "    result = evaluator.evaluate(\n",
    "        query=question,  # query_string\n",
    "        contexts=[context],  # retrieved_contexts\n",
    "    )\n",
    "\n",
    "    # fields to be updated in the database\n",
    "    fields = [\"context_relevancy_score\", \"context_relevancy_feedback\"]\n",
    "    # values to be updated in the database\n",
    "    values = [result.score, f\"{result.feedback}\"]\n",
    "\n",
    "    return fields, values"
   ],
   "id": "13261431b61bb875",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T06:29:57.780045Z",
     "start_time": "2024-06-13T06:29:57.769045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_correctness(evaluation_model, record):\n",
    "    \"\"\"\n",
    "    03 Correctness Evaluator\n",
    "    Evaluates the correctness of a question answering system.\n",
    "    This evaluator depends on `reference` answer to be provided, in addition to the\n",
    "    query string and response string.\n",
    "\n",
    "    Metric:\n",
    "    correctness_score (float)\n",
    "    correctness_feedback (str)\n",
    "    \"\"\"\n",
    "    context, question, reference_answer, response = get_record_data(record)\n",
    "\n",
    "    # evaluation\n",
    "    evaluator = CorrectnessEvaluator(llm=evaluation_model)\n",
    "    result = evaluator.evaluate(\n",
    "        query=question,  # query_string\n",
    "        contexts=[context],  # retrieved_contexts\n",
    "        response=response,  # response_string\n",
    "        reference=reference_answer  # reference_string\n",
    "    )\n",
    "\n",
    "    # fields to be updated in the database\n",
    "    fields = [\"correctness_score\", \"correctness_feedback\"]\n",
    "    # values to be updated in the database\n",
    "    values = [result.score, f\"{result.feedback}\"]\n",
    "\n",
    "    return fields, values"
   ],
   "id": "881291cc743ccb9d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T06:30:08.055209Z",
     "start_time": "2024-06-13T06:30:08.041871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_faithfulness(evaluation_model, record):\n",
    "    \"\"\"\n",
    "    04 Faithfulness Evaluator\n",
    "    Evaluates whether a response is faithful to the contexts\n",
    "    (i.e. whether the response is supported by the contexts or hallucinated.)\n",
    "\n",
    "    This evaluator only considers the response string and the list of context strings.\n",
    "\n",
    "    Metric:\n",
    "    faithfulness_score (float)\n",
    "    faithfulness_feedback (str)\n",
    "    \"\"\"\n",
    "    context, question, reference_answer, response = get_record_data(record)\n",
    "\n",
    "    # evaluation\n",
    "    evaluator = FaithfulnessEvaluator(llm=evaluation_model)\n",
    "    result = evaluator.evaluate(\n",
    "        contexts=[context],  # retrieved_contexts\n",
    "        response=response  # response_string\n",
    "    )\n",
    "\n",
    "    # fields to be updated in the database\n",
    "    fields = [\"faithfulness_score\"]\n",
    "    # values to be updated in the database\n",
    "    values = [result.score]\n",
    "\n",
    "    return fields, values"
   ],
   "id": "ea433cd15080cf38",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T06:30:08.795848Z",
     "start_time": "2024-06-13T06:30:08.785693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_relevancy(evaluation_model, record):\n",
    "    \"\"\"\n",
    "    05 Relevancy Evaluator\n",
    "    Evaluates the relevancy of retrieved contexts and response to a query.\n",
    "    This evaluator considers the query string, retrieved contexts, and response string.\n",
    "\n",
    "    Metric:\n",
    "    relevancy_score (float)\n",
    "    relevancy_feedback (str)\n",
    "    \"\"\"\n",
    "    context, question, reference_answer, response = get_record_data(record)\n",
    "\n",
    "    # evaluation\n",
    "    evaluator = RelevancyEvaluator(llm=evaluation_model)\n",
    "    result = evaluator.evaluate(\n",
    "        query=question,  # query_string\n",
    "        contexts=[context],  # retrieved_contexts\n",
    "        response=response  # response_string\n",
    "    )\n",
    "\n",
    "    # fields to be updated in the database\n",
    "    fields = [\"relevancy_score\", \"relevancy_feedback\"]\n",
    "    # values to be updated in the database\n",
    "    values = [result.score, f\"{result.feedback}\"]\n",
    "\n",
    "    return fields, values"
   ],
   "id": "32c9abc80a9ba078",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T06:30:09.496367Z",
     "start_time": "2024-06-13T06:30:09.473361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_pairwise(evaluation_model, record):\n",
    "    \"\"\"\n",
    "    06 Pairwise Comparison Evaluator\n",
    "    Evaluates the relevancy of two responses to a query.\n",
    "    This evaluator considers the query string, two responses, and the reference string.\n",
    "\n",
    "    Metric:\n",
    "    model_score (float)\n",
    "    \"\"\"\n",
    "    context, question, reference_answer, response = get_record_data(record)\n",
    "\n",
    "    # evaluation\n",
    "    evaluator = PairwiseComparisonEvaluator(llm=evaluation_model)\n",
    "    result = evaluator.evaluate(\n",
    "        query=question,  # query_string\n",
    "        reference=[context],  # reference_string\n",
    "        response=response,  # response_string\n",
    "        second_response=reference_answer  # second_response_string\n",
    "    )\n",
    "\n",
    "    # fields to be updated in the database\n",
    "    fields = [\"model_score\", \"model_feedback\"]\n",
    "    # values to be updated in the database\n",
    "    values = [result.score, f\"{result.feedback}\"]\n",
    "\n",
    "    return fields, values"
   ],
   "id": "4d813ac5672af929",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-13T14:10:30.302157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_test(\n",
    "        llm_model: str = \"llama3_instruct\",\n",
    "        collection: str = \"wiki_movie_plots_1024_100_mxbai\",\n",
    "        chat_mode: str = \"CONDENSE_PLUS_CONTEXT\"\n",
    "):\n",
    "    logging.info(\"LLM Model: oll_{} Collection: {} ChatMode: {}\".format(llm_model, collection, chat_mode))\n",
    "    \n",
    "    # get all the records from the test data db\n",
    "    get_records_for_evaluation = get_all_test_data(\n",
    "        llm=True,\n",
    "        llm_model=\"oll_\" + llm_model,\n",
    "        collection_name=collection,\n",
    "        chat_mode=chat_mode\n",
    "    )\n",
    "    \n",
    "    # get evaluation model: gpt-3.5-turbo\n",
    "    evaluation_model = get_evaluation_model()\n",
    "    \n",
    "    # loop through the records and evaluate them\n",
    "    for record in get_records_for_evaluation:\n",
    "        # 01 Answer Relevancy Evaluator\n",
    "        exists = get_current_evaluation(\n",
    "            evaluation=\"AnswerRelevancyEvaluator\",\n",
    "            llm_model=llm_model,\n",
    "            metric=\"answer_feedback\",\n",
    "            collection_name=collection,\n",
    "            chat_mode=chat_mode\n",
    "        )\n",
    "        if exists == 0 or exists < record[4]:\n",
    "            # evaluate the answer relevancy\n",
    "            fields, values = evaluate_answer_relenvancy(evaluation_model, record)\n",
    "            # update the record in the database\n",
    "            update_database(\n",
    "                fields=fields,\n",
    "                values=values,\n",
    "                llm=\"oll_\" + llm_model,\n",
    "                collection=collection,\n",
    "                row=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=\"AnswerRelevancyEvaluator\",\n",
    "                metric=\"answer_feedback\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "\n",
    "            # log the updated record\n",
    "            logging.info(f\"TEST INFO |:> AnswerRelevancyEvaluator - {record[4]} completed\")\n",
    "\n",
    "        # 02 Context Relevancy Evaluator\n",
    "        exists = get_current_evaluation(\n",
    "            evaluation=\"ContextRelevancyEvaluator\",\n",
    "            llm_model=llm_model,\n",
    "            metric=\"context_relevancy_score\",\n",
    "            collection_name=collection,\n",
    "            chat_mode=chat_mode\n",
    "        )\n",
    "        if exists == 0 or exists < record[4]:\n",
    "            # evaluate the context relevancy\n",
    "            fields, values = evaluate_context_relevancy(evaluation_model, record)\n",
    "\n",
    "            # update the record in the database\n",
    "            update_database(\n",
    "                fields=fields,\n",
    "                values=values,\n",
    "                llm=\"oll_\" + llm_model,\n",
    "                collection=collection,\n",
    "                row=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=\"ContextRelevancyEvaluator\",\n",
    "                metric=\"context_relevancy_score\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=\"ContextRelevancyEvaluator\",\n",
    "                metric=\"context_relevancy_feedback\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "\n",
    "            # log the updated record\n",
    "            logging.info(f\"TEST INFO |:> ContextRelevancyEvaluator - {record[4]} completed\")\n",
    "\n",
    "        # 03 Correctness Evaluator\n",
    "        evaluator = \"CorrectnessEvaluator\"\n",
    "        exists = get_current_evaluation(\n",
    "            evaluation=evaluator,\n",
    "            llm_model=llm_model,\n",
    "            metric=\"correctness_score\",\n",
    "            collection_name=collection,\n",
    "            chat_mode=chat_mode\n",
    "        )\n",
    "        if exists == 0 or exists < record[4]:\n",
    "            # evaluate the correctness\n",
    "            fields, values = evaluate_correctness(evaluation_model, record)\n",
    "\n",
    "            # update the record in the database\n",
    "            update_database(\n",
    "                fields=fields,\n",
    "                values=values,\n",
    "                llm=\"oll_\" + llm_model,\n",
    "                collection=collection,\n",
    "                row=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=evaluator,\n",
    "                metric=\"correctness_score\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=evaluator,\n",
    "                metric=\"correctness_feedback\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "\n",
    "            # log the updated record\n",
    "            logging.info(f\"TEST INFO |:> {evaluator} - {record[4]} completed\")\n",
    "\n",
    "        # 04 Faithfulness Evaluator\n",
    "        evaluator = \"FaithfulnessEvaluator\"\n",
    "        exists = get_current_evaluation(\n",
    "            evaluation=evaluator,\n",
    "            llm_model=llm_model,\n",
    "            metric=\"faithfulness_score\",\n",
    "            collection_name=collection,\n",
    "            chat_mode=chat_mode\n",
    "        )\n",
    "        if exists == 0 or exists < record[4]:\n",
    "            # evaluate the faithfulness\n",
    "            fields, values = evaluate_faithfulness(evaluation_model, record)\n",
    "\n",
    "            # update the record in the database\n",
    "            update_database(\n",
    "                fields=fields,\n",
    "                values=values,\n",
    "                llm=\"oll_\" + llm_model,\n",
    "                collection=collection,\n",
    "                row=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=evaluator,\n",
    "                metric=\"faithfulness_score\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "\n",
    "            # log the updated record\n",
    "            logging.info(f\"TEST INFO |:> {evaluator} - {record[4]} completed\")\n",
    "\n",
    "        # 05 Relevancy Evaluator\n",
    "        evaluator = \"RelevancyEvaluator\"\n",
    "        exists = get_current_evaluation(\n",
    "            evaluation=evaluator,\n",
    "            llm_model=llm_model,\n",
    "            metric=\"relevancy_score\",\n",
    "            collection_name=collection,\n",
    "            chat_mode=chat_mode\n",
    "        )\n",
    "        if exists == 0 or exists < record[4]:\n",
    "            # evaluate the relevancy\n",
    "            fields, values = evaluate_relevancy(evaluation_model, record)\n",
    "\n",
    "            # update the record in the database\n",
    "            update_database(\n",
    "                fields=fields,\n",
    "                values=values,\n",
    "                llm=\"oll_\" + llm_model,\n",
    "                collection=collection,\n",
    "                row=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=evaluator,\n",
    "                metric=\"relevancy_score\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=evaluator,\n",
    "                metric=\"relevancy_feedback\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "\n",
    "            # log the updated record\n",
    "            logging.info(f\"TEST INFO |:> {evaluator} - {record[4]} completed\")\n",
    "\n",
    "        # 06 Pairwise Comparison Evaluator\n",
    "        evaluator = \"PairwiseComparisonEvaluator\"\n",
    "        exists = get_current_evaluation(\n",
    "            evaluation=evaluator,\n",
    "            llm_model=llm_model,\n",
    "            metric=\"model_score\",\n",
    "            collection_name=collection,\n",
    "            chat_mode=chat_mode\n",
    "        )\n",
    "        if exists == 0 or exists < record[4]:\n",
    "            # evaluate the pairwise comparison\n",
    "            fields, values = evaluate_pairwise(evaluation_model, record)\n",
    "\n",
    "            # update the record in the database\n",
    "            update_database(\n",
    "                fields=fields,\n",
    "                values=values,\n",
    "                llm=\"oll_\" + llm_model,\n",
    "                collection=collection,\n",
    "                row=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=evaluator,\n",
    "                metric=\"model_score\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "            update_evaluation(\n",
    "                evaluation_model=evaluator,\n",
    "                metric=\"model_feedback\",\n",
    "                llm_model=llm_model,\n",
    "                collection_name=collection,\n",
    "                question_id=record[4],\n",
    "                chat_mode=chat_mode\n",
    "            )\n",
    "\n",
    "            # log the updated record\n",
    "            logging.info(f\"TEST INFO |:> {evaluator} - {record[4]} completed\")\n",
    "\n",
    "    time.sleep(1)\n",
    "    logging.info(\"TEST INFO |:> Evaluation completed\")\n",
    "\n",
    "\n",
    "llms = [\"llama3_instruct\", \"gemma_instruct\", \"mistral_instruct\"]\n",
    "collections = [\n",
    "    \"wiki_movie_plots_512_50_mxbai\",\n",
    "    \"wiki_movie_plots_1024_100_mxbai\",\n",
    "    \"wiki_movie_plots_2048_200_mxbai\",\n",
    "]\n",
    "for llm in range(len(llms)):\n",
    "    for collection in range(len(collections)):\n",
    "        run_test(llm_model=llms[llm], collection=collections[collection], chat_mode=\"CONDENSE_PLUS_CONTEXT\")"
   ],
   "id": "273155dbd04a9e53",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 16:10:30,317 - INFO - LLM Model: oll_llama3_instruct Collection: wiki_movie_plots_512_50_mxbai ChatMode: CONDENSE_PLUS_CONTEXT\n",
      "2024-06-13 16:10:30,403 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-06-13 16:10:30,404 - DEBUG - load_verify_locations cafile='C:\\\\Users\\\\Alex\\\\anaconda3\\\\envs\\\\thesis_llm\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "2024-06-13 16:10:30,422 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert evaluation system for a question answering chatbot.\\n\\nYou are given the following information:\\n- a user query, and\\n- a generated answer\\n\\nYou may also be given a reference answer to use for reference in your evaluation.\\n\\nYour job is to judge the relevance and correctness of the generated answer.\\nOutput a single score that represents a holistic evaluation.\\nYou must return your response in a line with only the score.\\nDo not return answers in any other format.\\nOn a separate line provide your reasoning for the score as well.\\n\\nFollow these guidelines for scoring:\\n- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\\n- If the generated answer is not relevant to the user query, you should give a score of 1.\\n- If the generated answer is relevant but contains mistakes, you should give a score between 2 and 3.\\n- If the generated answer is relevant and fully correct, you should give a score between 4 and 5.\\n\\nExample Response:\\n4.0\\nThe generated answer has the exact same metrics as the reference answer,     but it is not as concise.\\n\\n'}, {'role': 'user', 'content': '\\n## User Query\\nrelease_year: 1984\\ntitle: The Karate Kid\\norigin_ethnicity: American\\ndirector: John G. Avildsen\\ncast: Ralph Macchio, Pat Morita, Elisabeth Shue, William Zabka, Martin Kove\\ngenre: drama\\nwiki_page: https://en.wikipedia.org/wiki/The_Karate_Kid_(1984_film)\\nplot: Daniel LaRusso and his mother move from Parsippany-Troy Hills, New Jersey to Reseda, Los Angeles, California. The maintenance man in their new apartment complex is an eccentric, kind and generous Okinawan immigrant named Mr. Miyagi.\\r\\nAt a beach party, Daniel meets Ali Mills, a high school cheerleader from Encino, Los Angeles. Johnny Lawrence, Ali\\'s ex-boyfriend, is the top student of a karate dojo called \"Cobra Kai.\" When Johnny deliberately breaks Ali\\'s radio, Daniel attempts to stop him, but is easily overpowered and humiliated by Johnny. Continuously bullied by the Cobra Kai after this, Daniel finds solace with Miyagi. At a Halloween party, Daniel douses Johnny with water; chased and eventually cornered by Johnny and his accomplices, Daniel is savagely beaten until Miyagi intervenes, easily disabling the attackers.\\r\\nDaniel asks Miyagi to teach him to fight. Miyagi refuses, instead agreeing to accompany Daniel to the Cobra Kai dojo to resolve the conflict. They meet with the sensei, John Kreese, an ex-Special Forces Vietnam veteran who teaches his students to be aggressive and merciless against their opponents. He dismisses the peace offering made by Miyagi, so Miyagi proposes that Daniel will enter the Under-18 All-Valley Karate Tournament, where he will compete against the Cobra Kai students, and requests that the bullying cease while Daniel trains. Kreese agrees to the terms, and warns that if Daniel does not appear at the tournament, the harassment will resume on both Daniel and Miyagi.\\r\\nDaniel\\'s \\'training\\' starts under the guise of having him complete various lengthy, menial chores that appear to have nothing to do with karate, but which are actually teaching muscle memory. Through Miyagi\\'s teaching, Daniel learns the necessity of personal balance, reflected in the principle that martial arts training is not so much about disciplining the body as it is the spirit.\\r\\nAt the tournament, Daniel unexpectedly reaches the semi-finals. After Daniel defeats a particularly skilled opponent, Kreese, worried that Daniel might make it to the finals, instructs Bobby Brown—one of his more compassionate students and the least vicious of Daniel\\'s tormentors—to disable Daniel with an illegal attack to the knee. Bobby reluctantly does so and is disqualified. Daniel, refusing to concede, convinces Miyagi to use a pain suppression technique so he can continue the tournament. Daniel, barely able to stand, uses a Crane kick, which allows him to deliver a blow to Johnny\\'s head using only one leg and wins the tournament. Johnny, having gained respect for his nemesis, gives Daniel his trophy and Daniel is carried off by the enthusiastic crowd.\\nplot_length: 2672\\n\\n## Reference Answer\\nThe director of the movie \"The Karate Kid\" released in 1984 is John G. Avildsen.\\n\\n## Generated Answer\\nAccording to the provided metadata and content, the director of the movie \"The Karate Kid\" released in 1984 is John G. Avildsen.\\n'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:30,424 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "2024-06-13 16:10:30,460 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001AC7CAB5370>\n",
      "2024-06-13 16:10:30,461 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AC7CA85E40> server_hostname='api.openai.com' timeout=60.0\n",
      "2024-06-13 16:10:30,478 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001AC7CAB5220>\n",
      "2024-06-13 16:10:30,479 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:30,480 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:30,481 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:30,482 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:32,123 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'1420'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78907'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'819ms'), (b'x-request-id', b'req_cbb65d111c649c68820108cfd085bbad'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hGsrMGBaNvg3FHbFyU6DRndz.TcPrT0wIMpG9aIMIdg-1718287831-1.0.1.1-.mImDxwfnx_j1HYo_OZCr6QgN00zFSMCSxsZfMynUKHyOO8crNA280XkrDTzPfrjAKvyfa8F.lh9u53GeknihA; path=/; expires=Thu, 13-Jun-24 14:40:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=WpEP0dPSNztb0enjpbfdRtZxUFaCs7p09r_Og9bv6g8-1718287831720-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa1a2c64371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:32,125 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:32,125 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:32,126 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:32,128 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:32,128 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:32,129 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:32,189 - INFO - Record updated in database\n",
      "2024-06-13 16:10:32,191 - INFO - TEST INFO |:> CorrectnessEvaluator - 0 completed\n",
      "2024-06-13 16:10:32,193 - DEBUG - > Adding chunk: Who is the director of the movie \"The Karate Ki...\n",
      "2024-06-13 16:10:32,204 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Please tell if a given piece of information is supported by the context.\\nYou need to answer with either YES or NO.\\nAnswer YES if any of the context supports the information, even if most of the context is unrelated. Some examples are provided below. \\n\\nInformation: Apple pie is generally double-crusted.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream (\\'apple pie à la mode\\'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: YES\\nInformation: Apple pies tastes bad.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream (\\'apple pie à la mode\\'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: NO\\nInformation: According to the provided metadata and content, the director of the movie \"The Karate Kid\" released in 1984 is John G. Avildsen.\\nContext: Who is the director of the movie \"The Karate Kid\" released in 1984?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:32,206 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:32,207 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:32,208 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:32,209 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:32,210 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:32,576 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'157'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79661'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'254ms'), (b'x-request-id', b'req_8e4925f6009f6b433cd7fb1cc844aad9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa24eafc371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:32,579 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:32,581 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:32,582 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:32,582 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:32,583 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:32,584 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:32,612 - INFO - Record updated in database\n",
      "2024-06-13 16:10:32,614 - INFO - TEST INFO |:> FaithfulnessEvaluator - 0 completed\n",
      "2024-06-13 16:10:32,623 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert evaluation system for a question answering chatbot.\\n\\nYou are given the following information:\\n- a user query, and\\n- a generated answer\\n\\nYou may also be given a reference answer to use for reference in your evaluation.\\n\\nYour job is to judge the relevance and correctness of the generated answer.\\nOutput a single score that represents a holistic evaluation.\\nYou must return your response in a line with only the score.\\nDo not return answers in any other format.\\nOn a separate line provide your reasoning for the score as well.\\n\\nFollow these guidelines for scoring:\\n- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\\n- If the generated answer is not relevant to the user query, you should give a score of 1.\\n- If the generated answer is relevant but contains mistakes, you should give a score between 2 and 3.\\n- If the generated answer is relevant and fully correct, you should give a score between 4 and 5.\\n\\nExample Response:\\n4.0\\nThe generated answer has the exact same metrics as the reference answer,     but it is not as concise.\\n\\n'}, {'role': 'user', 'content': '\\n## User Query\\nrelease_year: 1984\\ntitle: The Karate Kid\\norigin_ethnicity: American\\ndirector: John G. Avildsen\\ncast: Ralph Macchio, Pat Morita, Elisabeth Shue, William Zabka, Martin Kove\\ngenre: drama\\nwiki_page: https://en.wikipedia.org/wiki/The_Karate_Kid_(1984_film)\\nplot: Daniel LaRusso and his mother move from Parsippany-Troy Hills, New Jersey to Reseda, Los Angeles, California. The maintenance man in their new apartment complex is an eccentric, kind and generous Okinawan immigrant named Mr. Miyagi.\\r\\nAt a beach party, Daniel meets Ali Mills, a high school cheerleader from Encino, Los Angeles. Johnny Lawrence, Ali\\'s ex-boyfriend, is the top student of a karate dojo called \"Cobra Kai.\" When Johnny deliberately breaks Ali\\'s radio, Daniel attempts to stop him, but is easily overpowered and humiliated by Johnny. Continuously bullied by the Cobra Kai after this, Daniel finds solace with Miyagi. At a Halloween party, Daniel douses Johnny with water; chased and eventually cornered by Johnny and his accomplices, Daniel is savagely beaten until Miyagi intervenes, easily disabling the attackers.\\r\\nDaniel asks Miyagi to teach him to fight. Miyagi refuses, instead agreeing to accompany Daniel to the Cobra Kai dojo to resolve the conflict. They meet with the sensei, John Kreese, an ex-Special Forces Vietnam veteran who teaches his students to be aggressive and merciless against their opponents. He dismisses the peace offering made by Miyagi, so Miyagi proposes that Daniel will enter the Under-18 All-Valley Karate Tournament, where he will compete against the Cobra Kai students, and requests that the bullying cease while Daniel trains. Kreese agrees to the terms, and warns that if Daniel does not appear at the tournament, the harassment will resume on both Daniel and Miyagi.\\r\\nDaniel\\'s \\'training\\' starts under the guise of having him complete various lengthy, menial chores that appear to have nothing to do with karate, but which are actually teaching muscle memory. Through Miyagi\\'s teaching, Daniel learns the necessity of personal balance, reflected in the principle that martial arts training is not so much about disciplining the body as it is the spirit.\\r\\nAt the tournament, Daniel unexpectedly reaches the semi-finals. After Daniel defeats a particularly skilled opponent, Kreese, worried that Daniel might make it to the finals, instructs Bobby Brown—one of his more compassionate students and the least vicious of Daniel\\'s tormentors—to disable Daniel with an illegal attack to the knee. Bobby reluctantly does so and is disqualified. Daniel, refusing to concede, convinces Miyagi to use a pain suppression technique so he can continue the tournament. Daniel, barely able to stand, uses a Crane kick, which allows him to deliver a blow to Johnny\\'s head using only one leg and wins the tournament. Johnny, having gained respect for his nemesis, gives Daniel his trophy and Daniel is carried off by the enthusiastic crowd.\\nplot_length: 2672\\n\\n## Reference Answer\\nThe plot of \"The Karate Kid\" released in 1984 follows the story of Daniel LaRusso, who learns karate from Mr. Miyagi to stand up against bullies.\\n\\n## Generated Answer\\nBased on the provided content, here\\'s a summary of the plot:\\n\\nDaniel\\'s \\'training\\' starts under the guise of having him complete various lengthy, menial chores that appear to have nothing to do with karate, but which are actually teaching muscle memory. Through Miyagi\\'s teaching, Daniel learns the necessity of personal balance, reflected in the principle that martial arts training is not so much about disciplining the body as it is the spirit.\\n\\nAt the tournament, Daniel unexpectedly reaches the semi-finals. After Daniel defeats a particularly skilled opponent, Kreese, worried that Daniel might make it to the finals, instructs Bobby Brown—one of his more compassionate students and the least vicious of Daniel\\'s tormentors—to disable Daniel with an illegal attack to the knee. Bobby reluctantly does so and is disqualified. Daniel, refusing to concede, convinces Miyagi to use a pain suppression technique so he can continue the tournament. Daniel, barely able to stand, uses a Crane kick, which allows him to deliver a blow to Johnny\\'s head using only one leg and wins the tournament. Johnny, having gained respect for his nemesis, gives Daniel his trophy and Daniel is carried off by the enthusiastic crowd.\\n\\nPlease note that this summary is based on the provided content and might not be an exhaustive or definitive account of the movie\\'s plot.\\n'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:32,625 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:32,626 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:32,627 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:32,628 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:32,629 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:34,500 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'1570'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78583'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.062s'), (b'x-request-id', b'req_79d71dbeae0664590a90c83eb4f49077'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa278e50371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:34,501 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:34,502 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:34,503 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:34,504 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:34,505 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:34,506 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:34,551 - INFO - Record updated in database\n",
      "2024-06-13 16:10:34,562 - INFO - TEST INFO |:> CorrectnessEvaluator - 1 completed\n",
      "2024-06-13 16:10:34,564 - DEBUG - > Adding chunk: What is the plot of \"The Karate Kid\" released i...\n",
      "2024-06-13 16:10:34,575 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Please tell if a given piece of information is supported by the context.\\nYou need to answer with either YES or NO.\\nAnswer YES if any of the context supports the information, even if most of the context is unrelated. Some examples are provided below. \\n\\nInformation: Apple pie is generally double-crusted.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream (\\'apple pie à la mode\\'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: YES\\nInformation: Apple pies tastes bad.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream (\\'apple pie à la mode\\'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: NO\\nInformation: Based on the provided content, here\\'s a summary of the plot:\\n\\nDaniel\\'s \\'training\\' starts under the guise of having him complete various lengthy, menial chores that appear to have nothing to do with karate, but which are actually teaching muscle memory. Through Miyagi\\'s teaching, Daniel learns the necessity of personal balance, reflected in the principle that martial arts training is not so much about disciplining the body as it is the spirit.\\n\\nAt the tournament, Daniel unexpectedly reaches the semi-finals. After Daniel defeats a particularly skilled opponent, Kreese, worried that Daniel might make it to the finals, instructs Bobby Brown—one of his more compassionate students and the least vicious of Daniel\\'s tormentors—to disable Daniel with an illegal attack to the knee. Bobby reluctantly does so and is disqualified. Daniel, refusing to concede, convinces Miyagi to use a pain suppression technique so he can continue the tournament. Daniel, barely able to stand, uses a Crane kick, which allows him to deliver a blow to Johnny\\'s head using only one leg and wins the tournament. Johnny, having gained respect for his nemesis, gives Daniel his trophy and Daniel is carried off by the enthusiastic crowd.\\n\\nPlease note that this summary is based on the provided content and might not be an exhaustive or definitive account of the movie\\'s plot.\\nContext: What is the plot of \"The Karate Kid\" released in 1984?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:34,577 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:34,578 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:34,579 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:34,580 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:34,580 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:35,186 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'383'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79357'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'482ms'), (b'x-request-id', b'req_ed2876c153f49811474d07a679ea3966'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa33bf57371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:35,187 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:35,188 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:35,189 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:35,190 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:35,191 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:35,192 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:35,219 - INFO - Record updated in database\n",
      "2024-06-13 16:10:35,224 - INFO - TEST INFO |:> FaithfulnessEvaluator - 1 completed\n",
      "2024-06-13 16:10:35,233 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert evaluation system for a question answering chatbot.\\n\\nYou are given the following information:\\n- a user query, and\\n- a generated answer\\n\\nYou may also be given a reference answer to use for reference in your evaluation.\\n\\nYour job is to judge the relevance and correctness of the generated answer.\\nOutput a single score that represents a holistic evaluation.\\nYou must return your response in a line with only the score.\\nDo not return answers in any other format.\\nOn a separate line provide your reasoning for the score as well.\\n\\nFollow these guidelines for scoring:\\n- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\\n- If the generated answer is not relevant to the user query, you should give a score of 1.\\n- If the generated answer is relevant but contains mistakes, you should give a score between 2 and 3.\\n- If the generated answer is relevant and fully correct, you should give a score between 4 and 5.\\n\\nExample Response:\\n4.0\\nThe generated answer has the exact same metrics as the reference answer,     but it is not as concise.\\n\\n'}, {'role': 'user', 'content': '\\n## User Query\\nrelease_year: 1984\\ntitle: The Karate Kid\\norigin_ethnicity: American\\ndirector: John G. Avildsen\\ncast: Ralph Macchio, Pat Morita, Elisabeth Shue, William Zabka, Martin Kove\\ngenre: drama\\nwiki_page: https://en.wikipedia.org/wiki/The_Karate_Kid_(1984_film)\\nplot: Daniel LaRusso and his mother move from Parsippany-Troy Hills, New Jersey to Reseda, Los Angeles, California. The maintenance man in their new apartment complex is an eccentric, kind and generous Okinawan immigrant named Mr. Miyagi.\\r\\nAt a beach party, Daniel meets Ali Mills, a high school cheerleader from Encino, Los Angeles. Johnny Lawrence, Ali\\'s ex-boyfriend, is the top student of a karate dojo called \"Cobra Kai.\" When Johnny deliberately breaks Ali\\'s radio, Daniel attempts to stop him, but is easily overpowered and humiliated by Johnny. Continuously bullied by the Cobra Kai after this, Daniel finds solace with Miyagi. At a Halloween party, Daniel douses Johnny with water; chased and eventually cornered by Johnny and his accomplices, Daniel is savagely beaten until Miyagi intervenes, easily disabling the attackers.\\r\\nDaniel asks Miyagi to teach him to fight. Miyagi refuses, instead agreeing to accompany Daniel to the Cobra Kai dojo to resolve the conflict. They meet with the sensei, John Kreese, an ex-Special Forces Vietnam veteran who teaches his students to be aggressive and merciless against their opponents. He dismisses the peace offering made by Miyagi, so Miyagi proposes that Daniel will enter the Under-18 All-Valley Karate Tournament, where he will compete against the Cobra Kai students, and requests that the bullying cease while Daniel trains. Kreese agrees to the terms, and warns that if Daniel does not appear at the tournament, the harassment will resume on both Daniel and Miyagi.\\r\\nDaniel\\'s \\'training\\' starts under the guise of having him complete various lengthy, menial chores that appear to have nothing to do with karate, but which are actually teaching muscle memory. Through Miyagi\\'s teaching, Daniel learns the necessity of personal balance, reflected in the principle that martial arts training is not so much about disciplining the body as it is the spirit.\\r\\nAt the tournament, Daniel unexpectedly reaches the semi-finals. After Daniel defeats a particularly skilled opponent, Kreese, worried that Daniel might make it to the finals, instructs Bobby Brown—one of his more compassionate students and the least vicious of Daniel\\'s tormentors—to disable Daniel with an illegal attack to the knee. Bobby reluctantly does so and is disqualified. Daniel, refusing to concede, convinces Miyagi to use a pain suppression technique so he can continue the tournament. Daniel, barely able to stand, uses a Crane kick, which allows him to deliver a blow to Johnny\\'s head using only one leg and wins the tournament. Johnny, having gained respect for his nemesis, gives Daniel his trophy and Daniel is carried off by the enthusiastic crowd.\\nplot_length: 2672\\n\\n## Reference Answer\\nThe genre of the movie \"The Karate Kid\" released in 1984 is drama.\\n\\n## Generated Answer\\nAccording to the provided metadata, the genre of the movie \"The Karate Kid\" released in 1984 is drama.\\n'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:35,236 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:35,237 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:35,238 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:35,239 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:35,240 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:36,431 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'888'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78917'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'812ms'), (b'x-request-id', b'req_cfa6afdaabe935684c1cb9f3d48afd2b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa37dcfc371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:36,431 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:36,432 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:36,433 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:36,433 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:36,434 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:36,435 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:36,481 - INFO - Record updated in database\n",
      "2024-06-13 16:10:36,493 - INFO - TEST INFO |:> CorrectnessEvaluator - 2 completed\n",
      "2024-06-13 16:10:36,495 - DEBUG - > Adding chunk: What is the genre of the movie \"The Karate Kid\"...\n",
      "2024-06-13 16:10:36,506 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Please tell if a given piece of information is supported by the context.\\nYou need to answer with either YES or NO.\\nAnswer YES if any of the context supports the information, even if most of the context is unrelated. Some examples are provided below. \\n\\nInformation: Apple pie is generally double-crusted.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream (\\'apple pie à la mode\\'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: YES\\nInformation: Apple pies tastes bad.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream (\\'apple pie à la mode\\'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: NO\\nInformation: According to the provided metadata, the genre of the movie \"The Karate Kid\" released in 1984 is drama.\\nContext: What is the genre of the movie \"The Karate Kid\" released in 1984?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:36,508 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:36,509 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:36,510 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:36,511 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:36,512 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:36,962 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79668'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_c3232e6c522d33b1c7da481c3a129f23'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa3fd803371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:36,968 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:36,971 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:36,976 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:36,980 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:36,982 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:36,985 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:37,017 - INFO - Record updated in database\n",
      "2024-06-13 16:10:37,023 - INFO - TEST INFO |:> FaithfulnessEvaluator - 2 completed\n",
      "2024-06-13 16:10:37,034 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert evaluation system for a question answering chatbot.\\n\\nYou are given the following information:\\n- a user query, and\\n- a generated answer\\n\\nYou may also be given a reference answer to use for reference in your evaluation.\\n\\nYour job is to judge the relevance and correctness of the generated answer.\\nOutput a single score that represents a holistic evaluation.\\nYou must return your response in a line with only the score.\\nDo not return answers in any other format.\\nOn a separate line provide your reasoning for the score as well.\\n\\nFollow these guidelines for scoring:\\n- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\\n- If the generated answer is not relevant to the user query, you should give a score of 1.\\n- If the generated answer is relevant but contains mistakes, you should give a score between 2 and 3.\\n- If the generated answer is relevant and fully correct, you should give a score between 4 and 5.\\n\\nExample Response:\\n4.0\\nThe generated answer has the exact same metrics as the reference answer,     but it is not as concise.\\n\\n'}, {'role': 'user', 'content': '\\n## User Query\\nrelease_year: 2016\\ntitle: Hands of Stone\\norigin_ethnicity: American\\ndirector: Jonathan Jakubowicz\\ncast: Édgar Ramírez, Robert De Niro\\ngenre: sports\\nwiki_page: https://en.wikipedia.org/wiki/Hands_of_Stone\\nplot: The film follows the life of Panamanian boxing legend Roberto Durán, who made his professional boxing debut in 1968 as a 16-year-old and retired in 2001 at age 50.\\r\\nGrowing up in Panama, Durán is homeschooled by Chaflan, who teaches young Roberto some vital life lessons. Later, Duran joins a boxing club with Nestor \"Plomo\" Quiñones as his coach.\\r\\nAs he reaches 20, an American legendary boxing trainer Ray Arcel, who nearly lost his life after being attacked by an unknown assailant in 1953 in New York City and is now living with his wife Stephanie, notices Roberto\\'s raw talent and punching power and takes the young fighter under his wing, becoming his coach. Not long after, Durán then meets a student, Felicidad, with whom he later has five children.\\r\\nAfter his fights through the 70s and 80s, rising through the divisions with phenomenal success (just one loss) he challenges Sugar Ray Leonard, dubbed as the \"Fighter of the Year.\" However, Durán is disrespectful of Leonard, describing him as a \"clown\" and confidently predicts a knock out win for himself.\\r\\nOne night, Durán confronts Leonard in front of his wife and insults him by calling him a \"homosexual.\" The incident frustrates Ray. Durán\\'s hard feelings for Ray, on the other hand seem to stem from his resentment of Americans in general, because he recalls the ill-treatment meted out by the Americans to the nation of Panama, remembering how American troops took over the country by owning the Panama Canal — leading to conflict between the sides in 1964.\\r\\nIn June 1980, the day of fight between Durán and Leonard in which the venue is in Montreal, Durán wins via Unanimous decision as a Welterweight Champion (148-147, 145-144, 146-144). After the fight, Leonard states that being insulted is a strategy and calls for a rematch with an $8 million purse. At the house party, informed by his manager Carlos Eleta, Durán reluctantly agrees to the rematch. Chaflan is killed after being run over by a truck.\\r\\nIn November 1980, Durán and Leonard face at the ring for the second time, this time the venue is in New Orleans. But in the eighth round, the people of Panama are shocked when Durán gives up by saying \"No más\" (English: \"No more\") to the referee, thus Leonard wins via technical knockout (68–66, 68–66, and 67–66).\\r\\nUpon returning home in Panama, he faces angry protests. Durán tells his wife that he regrets letting them down and needs to go back in the ring in order to regain his popularity and the forgiveness of his fans. Due to this incident, Arcel is retired from his training and tells Durán that Plomo will be his coach. In June 1983, New York City, the day of his fight against Davey Moore, Leonard gratefully meets Durán for the first time since the rematch, saying that he forgives Durán. He tells Leonard that he gives his apology to his wife. At the fight with Moore up to the eighth round, now Leonard is now commentator, Durán won via technical knockout, eventually restores his popularity and pride by the people of Panama.\\r\\nIn the film\\'s epilogue, it states that Plomo was in Durán\\'s side for each fight until his death in 2012; Leonard and Durán remain friends until now; Ray was the first boxing trainer to be elected to the Boxing Hall of Fame and died of leukemia in 1994 after the six-year battle.\\nplot_length: 3295\\n\\n## Reference Answer\\nRay Arcel, an American legendary boxing trainer, noticed Durán\\'s talent and became his coach.\\n\\n## Generated Answer\\nAccording to the provided content, the legendary boxing trainer who took Roberto Durán under his wing was Ray Arcel.\\n'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:37,037 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:37,038 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:37,038 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:37,039 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:37,040 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:38,286 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'859'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78756'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'933ms'), (b'x-request-id', b'req_c034a9cb216a6a3355cfb9ab37e38b19'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa431cbf371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:38,287 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:38,288 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:38,288 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:38,290 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:38,291 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:38,292 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:38,338 - INFO - Record updated in database\n",
      "2024-06-13 16:10:38,349 - INFO - TEST INFO |:> CorrectnessEvaluator - 3 completed\n",
      "2024-06-13 16:10:38,352 - DEBUG - > Adding chunk: Who was the legendary boxing trainer that took ...\n",
      "2024-06-13 16:10:38,364 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Please tell if a given piece of information is supported by the context.\\nYou need to answer with either YES or NO.\\nAnswer YES if any of the context supports the information, even if most of the context is unrelated. Some examples are provided below. \\n\\nInformation: Apple pie is generally double-crusted.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream ('apple pie à la mode'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: YES\\nInformation: Apple pies tastes bad.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream ('apple pie à la mode'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: NO\\nInformation: According to the provided content, the legendary boxing trainer who took Roberto Durán under his wing was Ray Arcel.\\nContext: Who was the legendary boxing trainer that took Roberto Durán under his wing?\\nAnswer: \"}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:38,366 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:38,367 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:38,367 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:38,368 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:38,369 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:38,792 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'144'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79661'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'254ms'), (b'x-request-id', b'req_d2e64b3e98e3e8a5cc82850c2b6a26e9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa4b6f40371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:38,793 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:38,794 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:38,795 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:38,797 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:38,797 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:38,798 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:38,826 - INFO - Record updated in database\n",
      "2024-06-13 16:10:38,832 - INFO - TEST INFO |:> FaithfulnessEvaluator - 3 completed\n",
      "2024-06-13 16:10:38,842 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert evaluation system for a question answering chatbot.\\n\\nYou are given the following information:\\n- a user query, and\\n- a generated answer\\n\\nYou may also be given a reference answer to use for reference in your evaluation.\\n\\nYour job is to judge the relevance and correctness of the generated answer.\\nOutput a single score that represents a holistic evaluation.\\nYou must return your response in a line with only the score.\\nDo not return answers in any other format.\\nOn a separate line provide your reasoning for the score as well.\\n\\nFollow these guidelines for scoring:\\n- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\\n- If the generated answer is not relevant to the user query, you should give a score of 1.\\n- If the generated answer is relevant but contains mistakes, you should give a score between 2 and 3.\\n- If the generated answer is relevant and fully correct, you should give a score between 4 and 5.\\n\\nExample Response:\\n4.0\\nThe generated answer has the exact same metrics as the reference answer,     but it is not as concise.\\n\\n'}, {'role': 'user', 'content': '\\n## User Query\\nrelease_year: 2016\\ntitle: Hands of Stone\\norigin_ethnicity: American\\ndirector: Jonathan Jakubowicz\\ncast: Édgar Ramírez, Robert De Niro\\ngenre: sports\\nwiki_page: https://en.wikipedia.org/wiki/Hands_of_Stone\\nplot: The film follows the life of Panamanian boxing legend Roberto Durán, who made his professional boxing debut in 1968 as a 16-year-old and retired in 2001 at age 50.\\r\\nGrowing up in Panama, Durán is homeschooled by Chaflan, who teaches young Roberto some vital life lessons. Later, Duran joins a boxing club with Nestor \"Plomo\" Quiñones as his coach.\\r\\nAs he reaches 20, an American legendary boxing trainer Ray Arcel, who nearly lost his life after being attacked by an unknown assailant in 1953 in New York City and is now living with his wife Stephanie, notices Roberto\\'s raw talent and punching power and takes the young fighter under his wing, becoming his coach. Not long after, Durán then meets a student, Felicidad, with whom he later has five children.\\r\\nAfter his fights through the 70s and 80s, rising through the divisions with phenomenal success (just one loss) he challenges Sugar Ray Leonard, dubbed as the \"Fighter of the Year.\" However, Durán is disrespectful of Leonard, describing him as a \"clown\" and confidently predicts a knock out win for himself.\\r\\nOne night, Durán confronts Leonard in front of his wife and insults him by calling him a \"homosexual.\" The incident frustrates Ray. Durán\\'s hard feelings for Ray, on the other hand seem to stem from his resentment of Americans in general, because he recalls the ill-treatment meted out by the Americans to the nation of Panama, remembering how American troops took over the country by owning the Panama Canal — leading to conflict between the sides in 1964.\\r\\nIn June 1980, the day of fight between Durán and Leonard in which the venue is in Montreal, Durán wins via Unanimous decision as a Welterweight Champion (148-147, 145-144, 146-144). After the fight, Leonard states that being insulted is a strategy and calls for a rematch with an $8 million purse. At the house party, informed by his manager Carlos Eleta, Durán reluctantly agrees to the rematch. Chaflan is killed after being run over by a truck.\\r\\nIn November 1980, Durán and Leonard face at the ring for the second time, this time the venue is in New Orleans. But in the eighth round, the people of Panama are shocked when Durán gives up by saying \"No más\" (English: \"No more\") to the referee, thus Leonard wins via technical knockout (68–66, 68–66, and 67–66).\\r\\nUpon returning home in Panama, he faces angry protests. Durán tells his wife that he regrets letting them down and needs to go back in the ring in order to regain his popularity and the forgiveness of his fans. Due to this incident, Arcel is retired from his training and tells Durán that Plomo will be his coach. In June 1983, New York City, the day of his fight against Davey Moore, Leonard gratefully meets Durán for the first time since the rematch, saying that he forgives Durán. He tells Leonard that he gives his apology to his wife. At the fight with Moore up to the eighth round, now Leonard is now commentator, Durán won via technical knockout, eventually restores his popularity and pride by the people of Panama.\\r\\nIn the film\\'s epilogue, it states that Plomo was in Durán\\'s side for each fight until his death in 2012; Leonard and Durán remain friends until now; Ray was the first boxing trainer to be elected to the Boxing Hall of Fame and died of leukemia in 1994 after the six-year battle.\\nplot_length: 3295\\n\\n## Reference Answer\\nDurán famously gave up by saying \"No más\" to the referee in the eighth round, leading to Leonard winning via technical knockout.\\n\\n## Generated Answer\\nAccording to the provided content, in November 1980, Roberto Durán and Sugar Ray Leonard faced each other for the second time, with the venue being New Orleans. However, in the eighth round, Roberto Durán gave up by saying \"No más\" (English: \"No more\") to the referee, thus Sugar Ray Leonard won via technical knockout (68–66, 68–66, and 67–66).\\n'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:38,845 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:38,846 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:38,847 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:38,848 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:38,848 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:40,676 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'1535'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78687'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'984ms'), (b'x-request-id', b'req_c0a267e6d14070a66272d6277bdffbd2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa4e6b58371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:40,680 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:40,681 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:40,682 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:40,683 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:40,684 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:40,685 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:40,731 - INFO - Record updated in database\n",
      "2024-06-13 16:10:40,743 - INFO - TEST INFO |:> CorrectnessEvaluator - 4 completed\n",
      "2024-06-13 16:10:40,745 - DEBUG - > Adding chunk: What was the result of the rematch between Robe...\n",
      "2024-06-13 16:10:40,759 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Please tell if a given piece of information is supported by the context.\\nYou need to answer with either YES or NO.\\nAnswer YES if any of the context supports the information, even if most of the context is unrelated. Some examples are provided below. \\n\\nInformation: Apple pie is generally double-crusted.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream (\\'apple pie à la mode\\'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: YES\\nInformation: Apple pies tastes bad.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream (\\'apple pie à la mode\\'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: NO\\nInformation: According to the provided content, in November 1980, Roberto Durán and Sugar Ray Leonard faced each other for the second time, with the venue being New Orleans. However, in the eighth round, Roberto Durán gave up by saying \"No más\" (English: \"No more\") to the referee, thus Sugar Ray Leonard won via technical knockout (68–66, 68–66, and 67–66).\\nContext: What was the result of the rematch between Roberto Durán and Sugar Ray Leonard?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:40,760 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:40,761 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:40,762 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:40,763 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:40,763 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:41,179 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'126'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79601'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'299ms'), (b'x-request-id', b'req_69c8436fab507b510c687ea7c2736724'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa5a6b92371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:41,180 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:41,181 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:41,182 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:41,182 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:41,183 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:41,183 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:41,212 - INFO - Record updated in database\n",
      "2024-06-13 16:10:41,219 - INFO - TEST INFO |:> FaithfulnessEvaluator - 4 completed\n",
      "2024-06-13 16:10:41,229 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert evaluation system for a question answering chatbot.\\n\\nYou are given the following information:\\n- a user query, and\\n- a generated answer\\n\\nYou may also be given a reference answer to use for reference in your evaluation.\\n\\nYour job is to judge the relevance and correctness of the generated answer.\\nOutput a single score that represents a holistic evaluation.\\nYou must return your response in a line with only the score.\\nDo not return answers in any other format.\\nOn a separate line provide your reasoning for the score as well.\\n\\nFollow these guidelines for scoring:\\n- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\\n- If the generated answer is not relevant to the user query, you should give a score of 1.\\n- If the generated answer is relevant but contains mistakes, you should give a score between 2 and 3.\\n- If the generated answer is relevant and fully correct, you should give a score between 4 and 5.\\n\\nExample Response:\\n4.0\\nThe generated answer has the exact same metrics as the reference answer,     but it is not as concise.\\n\\n'}, {'role': 'user', 'content': '\\n## User Query\\nrelease_year: 2016\\ntitle: Hands of Stone\\norigin_ethnicity: American\\ndirector: Jonathan Jakubowicz\\ncast: Édgar Ramírez, Robert De Niro\\ngenre: sports\\nwiki_page: https://en.wikipedia.org/wiki/Hands_of_Stone\\nplot: The film follows the life of Panamanian boxing legend Roberto Durán, who made his professional boxing debut in 1968 as a 16-year-old and retired in 2001 at age 50.\\r\\nGrowing up in Panama, Durán is homeschooled by Chaflan, who teaches young Roberto some vital life lessons. Later, Duran joins a boxing club with Nestor \"Plomo\" Quiñones as his coach.\\r\\nAs he reaches 20, an American legendary boxing trainer Ray Arcel, who nearly lost his life after being attacked by an unknown assailant in 1953 in New York City and is now living with his wife Stephanie, notices Roberto\\'s raw talent and punching power and takes the young fighter under his wing, becoming his coach. Not long after, Durán then meets a student, Felicidad, with whom he later has five children.\\r\\nAfter his fights through the 70s and 80s, rising through the divisions with phenomenal success (just one loss) he challenges Sugar Ray Leonard, dubbed as the \"Fighter of the Year.\" However, Durán is disrespectful of Leonard, describing him as a \"clown\" and confidently predicts a knock out win for himself.\\r\\nOne night, Durán confronts Leonard in front of his wife and insults him by calling him a \"homosexual.\" The incident frustrates Ray. Durán\\'s hard feelings for Ray, on the other hand seem to stem from his resentment of Americans in general, because he recalls the ill-treatment meted out by the Americans to the nation of Panama, remembering how American troops took over the country by owning the Panama Canal — leading to conflict between the sides in 1964.\\r\\nIn June 1980, the day of fight between Durán and Leonard in which the venue is in Montreal, Durán wins via Unanimous decision as a Welterweight Champion (148-147, 145-144, 146-144). After the fight, Leonard states that being insulted is a strategy and calls for a rematch with an $8 million purse. At the house party, informed by his manager Carlos Eleta, Durán reluctantly agrees to the rematch. Chaflan is killed after being run over by a truck.\\r\\nIn November 1980, Durán and Leonard face at the ring for the second time, this time the venue is in New Orleans. But in the eighth round, the people of Panama are shocked when Durán gives up by saying \"No más\" (English: \"No more\") to the referee, thus Leonard wins via technical knockout (68–66, 68–66, and 67–66).\\r\\nUpon returning home in Panama, he faces angry protests. Durán tells his wife that he regrets letting them down and needs to go back in the ring in order to regain his popularity and the forgiveness of his fans. Due to this incident, Arcel is retired from his training and tells Durán that Plomo will be his coach. In June 1983, New York City, the day of his fight against Davey Moore, Leonard gratefully meets Durán for the first time since the rematch, saying that he forgives Durán. He tells Leonard that he gives his apology to his wife. At the fight with Moore up to the eighth round, now Leonard is now commentator, Durán won via technical knockout, eventually restores his popularity and pride by the people of Panama.\\r\\nIn the film\\'s epilogue, it states that Plomo was in Durán\\'s side for each fight until his death in 2012; Leonard and Durán remain friends until now; Ray was the first boxing trainer to be elected to the Boxing Hall of Fame and died of leukemia in 1994 after the six-year battle.\\nplot_length: 3295\\n\\n## Reference Answer\\nDurán restored his popularity and pride by winning a fight against Davey Moore via technical knockout, with Leonard forgiving him and the people of Panama supporting him.\\n\\n## Generated Answer\\nAccording to the provided content, Roberto Durán eventually regained his popularity and pride by winning a fight against Davey Moore via technical knockout (up to the eighth round) with Sugar Ray Leonard as the commentator. This victory restored his popularity and pride among the people of Panama.\\n'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:41,232 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:41,233 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:41,234 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:41,235 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:41,236 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:43,062 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'1596'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78691'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'981ms'), (b'x-request-id', b'req_198fed66fc524055b495dadf588e9ca9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa5d5fbf371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:43,064 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:43,064 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:43,065 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:43,065 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:43,066 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:43,067 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:43,125 - INFO - Record updated in database\n",
      "2024-06-13 16:10:43,140 - INFO - TEST INFO |:> CorrectnessEvaluator - 5 completed\n",
      "2024-06-13 16:10:43,142 - DEBUG - > Adding chunk: How did Roberto Durán eventually regain his pop...\n",
      "2024-06-13 16:10:43,152 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Please tell if a given piece of information is supported by the context.\\nYou need to answer with either YES or NO.\\nAnswer YES if any of the context supports the information, even if most of the context is unrelated. Some examples are provided below. \\n\\nInformation: Apple pie is generally double-crusted.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream ('apple pie à la mode'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: YES\\nInformation: Apple pies tastes bad.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples. \\nApple pie is often served with whipped cream, ice cream ('apple pie à la mode'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: NO\\nInformation: According to the provided content, Roberto Durán eventually regained his popularity and pride by winning a fight against Davey Moore via technical knockout (up to the eighth round) with Sugar Ray Leonard as the commentator. This victory restored his popularity and pride among the people of Panama.\\nContext: How did Roberto Durán eventually regain his popularity and pride in the film?\\nAnswer: \"}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:43,154 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:43,155 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:43,156 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:43,157 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:43,158 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:43,706 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Jun 2024 14:10:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-sw38vhavpbii7axjqpqtehk3'), (b'openai-processing-ms', b'205'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79616'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'288ms'), (b'x-request-id', b'req_1dc492477281409285781decb2e9fbdc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8932aa695ff0371d-FRA'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-06-13 16:10:43,709 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-13 16:10:43,710 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:43,712 - DEBUG - receive_response_body.complete\n",
      "2024-06-13 16:10:43,712 - DEBUG - response_closed.started\n",
      "2024-06-13 16:10:43,715 - DEBUG - response_closed.complete\n",
      "2024-06-13 16:10:43,717 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-06-13 16:10:43,753 - INFO - Record updated in database\n",
      "2024-06-13 16:10:43,759 - INFO - TEST INFO |:> FaithfulnessEvaluator - 5 completed\n",
      "2024-06-13 16:10:43,769 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert evaluation system for a question answering chatbot.\\n\\nYou are given the following information:\\n- a user query, and\\n- a generated answer\\n\\nYou may also be given a reference answer to use for reference in your evaluation.\\n\\nYour job is to judge the relevance and correctness of the generated answer.\\nOutput a single score that represents a holistic evaluation.\\nYou must return your response in a line with only the score.\\nDo not return answers in any other format.\\nOn a separate line provide your reasoning for the score as well.\\n\\nFollow these guidelines for scoring:\\n- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\\n- If the generated answer is not relevant to the user query, you should give a score of 1.\\n- If the generated answer is relevant but contains mistakes, you should give a score between 2 and 3.\\n- If the generated answer is relevant and fully correct, you should give a score between 4 and 5.\\n\\nExample Response:\\n4.0\\nThe generated answer has the exact same metrics as the reference answer,     but it is not as concise.\\n\\n'}, {'role': 'user', 'content': '\\n## User Query\\nrelease_year: 2004\\ntitle:  Hair Show\\norigin_ethnicity: American\\ndirector: Leslie Small\\ncast: Kellita Smith, Mo\\'Nique, David Ramsey, Gina Torres\\ngenre: comedy\\nwiki_page: https://en.wikipedia.org/wiki/Hair_Show\\nplot: Peaches (Mo\\'Nique), a hair stylist from Baltimore, and her estranged sister, Angela (Kellita Smith), the owner of an upscale salon in Beverly Hills, get reacquainted when Peaches decides to attend a celebration for Angela in Los Angeles. The reunion is bittersweet and worsens when Angela finds out that Peaches is on the run from the IRS and only has 60 days to pay $50,000 in back taxes. After some hilarious moments and passionate exchanges, the two sisters join forces to fight off a pesky rival salon owner Marcella (Gina Torres) and save Peaches from her troubles by competing for a lucrative cash prize and bragging rights at the city\\'s annual hair show.\\nplot_length: 661\\n\\n## Reference Answer\\nThe main cast members are Kellita Smith, Mo\\'Nique, David Ramsey, and Gina Torres, with Mo\\'Nique and Kellita Smith playing the lead roles of Peaches and Angela.\\n\\n## Generated Answer\\nAccording to the provided content, the main cast members of the movie \"Hair Show\" are:\\n\\n* Mo\\'Nique\\n* Kellita Smith\\n* David Ramsey\\n* Gina Torres\\n'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-13 16:10:43,770 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:43,771 - DEBUG - send_request_headers.complete\n",
      "2024-06-13 16:10:43,772 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-13 16:10:43,773 - DEBUG - send_request_body.complete\n",
      "2024-06-13 16:10:43,774 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Improve Quality of Evaluation\n",
    "Some of the values went into the wrong field and therefore must be corrected."
   ],
   "id": "c50c2b92d2e25438"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Observation:**\n",
    "The correctness_score was mixed with the correctness_feedback. The following code will correct the values in the database."
   ],
   "id": "8236568301248695"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:51:41.699608Z",
     "start_time": "2024-06-13T15:51:15.631360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fix_issues(llm_model: str, collection: str, chat_mode: str):\n",
    "    # get the potential records to be updated\n",
    "    for record in get_all_test_data(llm=True, llm_model=\"oll_\" + llm_model, collection_name=collection, chat_mode=chat_mode):\n",
    "        # later indicator to update the database is:\n",
    "        llm_model = record[1]\n",
    "        question_id = record[4]\n",
    "        collection_name = record[3]\n",
    "    \n",
    "        correctness_score = record[12]\n",
    "        correctness_feedback = record[13]  # in this case, the correctness_score is in the feedback field\n",
    "    \n",
    "        if correctness_score == 0.0:\n",
    "    \n",
    "            correctness_score = correctness_feedback[:3]\n",
    "            # https://docs.python.org/3/library/re.html#:~:text=So%20r%22%5Cn%22%20is,using%20this%20raw%20string%20notation.\n",
    "            # \\n count as 1 character\n",
    "            correctness_feedback = correctness_feedback[4:]\n",
    "    \n",
    "            # check if correctness_score is a float\n",
    "            if float(correctness_score):\n",
    "                # update the record in the database\n",
    "                update_database(\n",
    "                    fields=[\"correctness_score\", \"correctness_feedback\"],\n",
    "                    values=[correctness_score, correctness_feedback],\n",
    "                    llm=llm_model,\n",
    "                    collection=collection_name,\n",
    "                    row=question_id,\n",
    "                    chat_mode=chat_mode\n",
    "                )\n",
    "                logging.info(f\"CORRECTION |:> correct values for - {question_id}\")\n",
    "        logging.info(f\"CORRECTION |:> Nothing to do for - {question_id}\")\n",
    "\n",
    "llms = [\n",
    "    \"llama3_instruct\",\n",
    "    \"gemma_instruct\",\n",
    "    \"mistral_instruct\"\n",
    "]\n",
    "collections = [\n",
    "    \"wiki_movie_plots_512_50_mxbai\",\n",
    "    \"wiki_movie_plots_1024_100_mxbai\",\n",
    "    \"wiki_movie_plots_2048_200_mxbai\",\n",
    "]\n",
    "chat_modes = [\n",
    "    \"CONDENSE_PLUS_CONTEXT\",\n",
    "    \"CONTEXT\"\n",
    "]\n",
    "for llm in range(len(llms)):\n",
    "    for collection in range(len(collections)):\n",
    "        for chat_mode in range(len(chat_modes)):\n",
    "            fix_issues(llm_model=llms[llm], collection=collections[collection], chat_mode=chat_modes[chat_mode])"
   ],
   "id": "15f6e10bb51b2325",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "15a854a14214607d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
