{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extract Questions and Context\n",
    "Now that we have extracted questions and facts (ground_truth) we are able to form a dataset for testing. The dataset will be created in the following steps:"
   ],
   "id": "c32b77d3608b172e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T08:35:35.282570Z",
     "start_time": "2024-06-05T08:35:35.277409Z"
    }
   },
   "source": [
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from utils.config import ROOT_DIR\n",
    "from utils.evaluation import load_object, load_questions_and_answers"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:35:35.288172Z",
     "start_time": "2024-06-05T08:35:35.285214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initialize logging for better debugging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ],
   "id": "e92ec39085539e1c",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Questions and Answers",
   "id": "fff1224aa6da2736"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:35:35.304207Z",
     "start_time": "2024-06-05T08:35:35.293865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = \"100_random\"\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "filename=f\"llm_qna_to_context_{model_name}_{dataset}.pkl\"\n",
    "folder=\"evaluation/data/\"\n",
    "questions = load_object(folder=folder, filename=filename)\n",
    "data = []"
   ],
   "id": "677e646eead485fd",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:35:35.308493Z",
     "start_time": "2024-06-05T08:35:35.305567Z"
    }
   },
   "cell_type": "code",
   "source": "logger.info(f\"Number of examples: {len(questions.examples)}\")",
   "id": "d5c0d0753d4c3f07",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Check Context\n",
    "The context should contain the following labels:\n",
    "- release_year\n",
    "- title\n",
    "- plot_length"
   ],
   "id": "bb827d5a659e0a34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:35:35.313136Z",
     "start_time": "2024-06-05T08:35:35.309413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_document(context_data):\n",
    "    labels = [\"release_year\", \"title\", \"plot_length\"]\n",
    "    labels_found = [label for label in labels if f\"{label}: \" in context_data]\n",
    "    labels_missing = [label for label in labels if label not in labels_found]\n",
    "    return {'labels_found': labels_found, 'labels_missing': labels_missing}"
   ],
   "id": "717c38c0eebdd1f1",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b964389df991a082"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create Dataset\n",
    "If the context only contains the label 'plot_length' the context will be added to the last created record. This is because it is a chunk that is referenced to another chunk.\n",
    "Every record will be created with the following structure:"
   ],
   "id": "785a7df41faa90af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:35:35.582816Z",
     "start_time": "2024-06-05T08:35:35.314705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index = 0\n",
    "for record in questions.examples:\n",
    "    item = {\n",
    "        'context': '',\n",
    "        'reference_answers': [],\n",
    "        'questions': [],\n",
    "        'answers': [],\n",
    "        'number_of_qnq': 0\n",
    "    }\n",
    "\n",
    "    # get context and add to item\n",
    "    context = record.reference_contexts[0]\n",
    "\n",
    "    # check labels in context\n",
    "    check_labels = check_document(context)\n",
    "\n",
    "    # the context contains 'release_year' and 'title'\n",
    "    release_year_title = all(label in check_labels['labels_found'] for label in [\"release_year\", \"title\"])\n",
    "\n",
    "    # the context only contains 'plot_length'\n",
    "    plot_length_only = all(label in check_labels['labels_missing'] for label in [\"release_year\", \"title\"])\n",
    "\n",
    "    # is query a question?\n",
    "    is_q_o = record.query.startswith(\"Q1:\")\n",
    "    is_q = record.query.startswith((\"Q1:\", \"Q2:\", \"Q3:\"))\n",
    "\n",
    "    # is query a ground_truth?\n",
    "    is_gt = record.query.startswith((\"A1:\", \"A2:\", \"A3:\"))\n",
    "\n",
    "    # query\n",
    "    q = record.query[4:]\n",
    "\n",
    "    if is_q_o and not plot_length_only:\n",
    "        item['context'] = context  # add context to item\n",
    "        data.append(item)  # append record\n",
    "        logger.info(f\"[{index}] Test-Record was created\")\n",
    "        index += 1  # increase index by 1\n",
    "    elif is_q_o and plot_length_only:\n",
    "        data[len(data)-1]['context'] += context\n",
    "\n",
    "    # current record\n",
    "    current_record = len(data) - 1  # represents the current index of the last created record\n",
    "\n",
    "    # field\n",
    "    field = 'questions' if is_q else 'reference_answers' if is_gt else ''\n",
    "\n",
    "    # add data\n",
    "    data[current_record][field].append(q)\n",
    "    if field == 'questions':\n",
    "        data[current_record]['number_of_qnq'] += 1\n",
    "    logger.info(f\"[{current_record}] Test-Record - added {field[:-1]}: {q}\")"
   ],
   "id": "273d921f7a896d1c",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_dataset(file_path, data):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)"
   ],
   "id": "9fcdfbdb075c6ea3",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_path = f\"{ROOT_DIR}/evaluation/data/llm_qna_to_context_{model_name}_{dataset}.json\"",
   "id": "bdde37f7ca30ee4e",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_dataset(save_path, data)",
   "id": "912eb0c0023ab9ae",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "qa_data = load_questions_and_answers(save_path)",
   "id": "eb4db76c86723252",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.DataFrame.from_dict(qa_data)",
   "id": "5e2dc999fba83e0",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we have for every of the 100 movies 3 rows with context, ground_truth and a question.\n",
    "- context\n",
    "- ground_truth (facts for 3 questions)\n",
    "- questions (3 questions)\n",
    "- answers (0 answers)\n",
    "We now need to split the questions and ground_truth into different rows.\n",
    "\n",
    "In the next Step every test in \\\"evaluation/test\\\" will be executed and written to a sqlite"
   ],
   "id": "82e185c025b6d23c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sum of all questions\n",
    "print(f\"Number of questions: {sum([item['number_of_qnq'] for item in data])}\")"
   ],
   "id": "137f09d3b78f45a4",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sum of all records\n",
    "print(f\"Number of records: {len(data)}\")"
   ],
   "id": "8d896c2a44357720",
   "execution_count": 39,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
